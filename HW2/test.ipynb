{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ijeongmin/Desktop/AI/AI/HW2/test.ipynb 셀 1\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ijeongmin/Desktop/AI/AI/HW2/test.ipynb#W0sZmlsZQ%3D%3D?line=246'>247</a>\u001b[0m I_target\u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39mtarget.png\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39m# MxN image\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ijeongmin/Desktop/AI/AI/HW2/test.ipynb#W0sZmlsZQ%3D%3D?line=248'>249</a>\u001b[0m I_template \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39mtemplate.png\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39m# mxn  face template\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/ijeongmin/Desktop/AI/AI/HW2/test.ipynb#W0sZmlsZQ%3D%3D?line=250'>251</a>\u001b[0m bounding_boxes \u001b[39m=\u001b[39m face_recognition(I_target, I_template)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ijeongmin/Desktop/AI/AI/HW2/test.ipynb#W0sZmlsZQ%3D%3D?line=252'>253</a>\u001b[0m I_target_c\u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39mtarget.png\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m# MxN image (just for visualization)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ijeongmin/Desktop/AI/AI/HW2/test.ipynb#W0sZmlsZQ%3D%3D?line=254'>255</a>\u001b[0m visualize_face_detection(I_target_c, bounding_boxes, I_template\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) \u001b[39m# visualization code\u001b[39;00m\n",
      "\u001b[1;32m/Users/ijeongmin/Desktop/AI/AI/HW2/test.ipynb 셀 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ijeongmin/Desktop/AI/AI/HW2/test.ipynb#W0sZmlsZQ%3D%3D?line=145'>146</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(w \u001b[39m-\u001b[39m w_tem):\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ijeongmin/Desktop/AI/AI/HW2/test.ipynb#W0sZmlsZQ%3D%3D?line=146'>147</a>\u001b[0m     \u001b[39m# print(str(i)+\", \" + str(j) )\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ijeongmin/Desktop/AI/AI/HW2/test.ipynb#W0sZmlsZQ%3D%3D?line=147'>148</a>\u001b[0m     I_temp \u001b[39m=\u001b[39m I_target[i:i\u001b[39m+\u001b[39mh_tem,j:j\u001b[39m+\u001b[39mw_tem]\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/ijeongmin/Desktop/AI/AI/HW2/test.ipynb#W0sZmlsZQ%3D%3D?line=149'>150</a>\u001b[0m     hog_image \u001b[39m=\u001b[39m extract_hog(I_temp)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ijeongmin/Desktop/AI/AI/HW2/test.ipynb#W0sZmlsZQ%3D%3D?line=150'>151</a>\u001b[0m     hog_image \u001b[39m=\u001b[39m hog_image \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mmean(hog_image)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ijeongmin/Desktop/AI/AI/HW2/test.ipynb#W0sZmlsZQ%3D%3D?line=151'>152</a>\u001b[0m     s \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(hog_image,hog_template)\u001b[39m/\u001b[39m(np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(hog_image,\u001b[39m2\u001b[39m)\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(hog_template,\u001b[39m2\u001b[39m))\n",
      "\u001b[1;32m/Users/ijeongmin/Desktop/AI/AI/HW2/test.ipynb 셀 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ijeongmin/Desktop/AI/AI/HW2/test.ipynb#W0sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mnormalize(im, \u001b[39mNone\u001b[39;00m, \u001b[39m0.0\u001b[39m, \u001b[39m1.0\u001b[39m, cv2\u001b[39m.\u001b[39mNORM_MINMAX, dtype\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mCV_32F)\u001b[39m# normalize\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ijeongmin/Desktop/AI/AI/HW2/test.ipynb#W0sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m filter_x, filter_y \u001b[39m=\u001b[39m get_differential_filter()\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/ijeongmin/Desktop/AI/AI/HW2/test.ipynb#W0sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m img_filtered_x \u001b[39m=\u001b[39m filter_image(img,filter_x)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ijeongmin/Desktop/AI/AI/HW2/test.ipynb#W0sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m img_filtered_y \u001b[39m=\u001b[39m filter_image(img,filter_y)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ijeongmin/Desktop/AI/AI/HW2/test.ipynb#W0sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m grad_mag, grad_ang \u001b[39m=\u001b[39m get_gradient(img_filtered_x,img_filtered_y)\n",
      "\u001b[1;32m/Users/ijeongmin/Desktop/AI/AI/HW2/test.ipynb 셀 1\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ijeongmin/Desktop/AI/AI/HW2/test.ipynb#W0sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m         \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,filter_height,\u001b[39m1\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ijeongmin/Desktop/AI/AI/HW2/test.ipynb#W0sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m             \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,filter_width,\u001b[39m1\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ijeongmin/Desktop/AI/AI/HW2/test.ipynb#W0sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m                 im_filtered[i,j] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39mpadded_im[i\u001b[39m+\u001b[39mk,j\u001b[39m+\u001b[39ml]\u001b[39m*\u001b[39m\u001b[39mfilter\u001b[39m[k,l]        \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ijeongmin/Desktop/AI/AI/HW2/test.ipynb#W0sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mreturn\u001b[39;00m im_filtered\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def get_differential_filter():\n",
    "    # TODO: implement this function\n",
    "    \n",
    "    # use sobel fiter for the gradient calculation\n",
    "    filter_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "    filter_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])    \n",
    "    return filter_x, filter_y\n",
    "\n",
    "\n",
    "def filter_image(im, filter):\n",
    "    # TODO: implement this function\n",
    "    \n",
    "    # in this function, apply the filter for the given image\n",
    "    # in this implementation, I restricted that image is always grayscale.\n",
    "    \n",
    "    image_height,image_width = im.shape# drop the channel element due to the assumption of this implementation\n",
    "    filter_height,filter_width = filter.shape\n",
    "    \n",
    "    # I tried to use zero padding method. I'm not consider the striding since I assume that our image is small enough.\n",
    "    padding_width = filter_width//2\n",
    "    padding_height = filter_height//2\n",
    "    \n",
    "    padded_im = np.pad(im,(padding_height,padding_width),mode = \"constant\")\n",
    "    \n",
    "    im_filtered = np.zeros((image_height,image_width))\n",
    "    \n",
    "    # do convolution\n",
    "    for i in range(0,image_height):\n",
    "        for j in range(0,image_width):\n",
    "            for k in range(0,filter_height,1):\n",
    "                for l in range(0,filter_width,1):\n",
    "                    im_filtered[i,j] +=padded_im[i+k,j+l]*filter[k,l]        \n",
    "    \n",
    "    return im_filtered\n",
    "\n",
    "# def filter_image(im, filter):\n",
    "#     return cv2.filter2D(im, -1, filter)\n",
    "\n",
    "\n",
    "\n",
    "def get_gradient(im_dx, im_dy):\n",
    "    # TODO: implement this function\n",
    "    grad_mag = np.sqrt(im_dx**2 + im_dy**2)\n",
    "    grad_angle = np.arctan2(im_dy, im_dx)\n",
    "    grad_angle[grad_angle < 0] += np.pi\n",
    "    return grad_mag, grad_angle\n",
    "\n",
    "\n",
    "def build_histogram(grad_mag, grad_angle, cell_size):\n",
    "    # TODO: implement this function\n",
    "    h,w = grad_mag.shape\n",
    "    h_cell = int(h/cell_size)\n",
    "    w_cell = int(w/cell_size)\n",
    "    \n",
    "    ori_histo = np.zeros(h_cell* w_cell*6, dtype=np.float32).reshape(h_cell,w_cell,6)\n",
    "    \n",
    "    \n",
    "    for i in range(h_cell):\n",
    "        for j in range(w_cell):\n",
    "            cell_ang = grad_angle[i*cell_size:(i+1)*cell_size, j*cell_size:(j+1)*cell_size]\n",
    "            cell_mag = grad_mag[i*cell_size:(i+1)*cell_size, j*cell_size:(j+1)*cell_size]\n",
    "            tmp_hist, _ = np.histogram(cell_ang, bins=6, range=(0, np.pi*2), weights=cell_mag)\n",
    "\n",
    "            # Accumulate the histogram values\n",
    "            ori_histo[i, j, :] = tmp_hist\n",
    "    return ori_histo\n",
    "\n",
    "\n",
    "def get_block_descriptor(ori_histo, block_size):\n",
    "    # TODO: implement this function\n",
    "    \n",
    "    h,w,_ = ori_histo.shape\n",
    "        \n",
    "    ori_histo_normalized = np.zeros((h-1,w-1,6*block_size*block_size))\n",
    "    \n",
    "    for i in range(h - block_size+1):\n",
    "        for j in range(w - block_size+1):\n",
    "            \n",
    "            tmp_hist = ori_histo[i:i+block_size,j:j+block_size,:].flatten()\n",
    "            tmp_hist /=np.sqrt(np.sum(tmp_hist**2) + 1e-6)\n",
    "            ori_histo_normalized[i,j,:] = tmp_hist\n",
    "    return ori_histo_normalized\n",
    "\n",
    "\n",
    "# visualize histogram of each block\n",
    "def visualize_hog(im, hog, cell_size, block_size):\n",
    "    num_bins = 6\n",
    "    max_len = 7  # control sum of segment lengths for visualized histogram bin of each block\n",
    "    im_h, im_w = im.shape\n",
    "    num_cell_h, num_cell_w = int(im_h / cell_size), int(im_w / cell_size)\n",
    "    num_blocks_h, num_blocks_w = num_cell_h - block_size + 1, num_cell_w - block_size + 1\n",
    "    \n",
    "    histo_normalized = hog.reshape((num_blocks_h, num_blocks_w, block_size**2, num_bins))\n",
    "    histo_normalized_vis = np.sum(histo_normalized**2, axis=2) * max_len  # num_blocks_h x num_blocks_w x num_bins\n",
    "    \n",
    "    angles = np.arange(0, np.pi, np.pi/num_bins)\n",
    "    mesh_x, mesh_y = np.meshgrid(np.r_[cell_size: cell_size*num_cell_w: cell_size], np.r_[cell_size: cell_size*num_cell_h: cell_size])\n",
    "    mesh_u = histo_normalized_vis * np.sin(angles).reshape((1, 1, num_bins))  # expand to same dims as histo_normalized\n",
    "    mesh_v = histo_normalized_vis * -np.cos(angles).reshape((1, 1, num_bins))  # expand to same dims as histo_normalized\n",
    "\n",
    "    \n",
    "    plt.imshow(im, cmap='gray', vmin=0, vmax=1)\n",
    "    for i in range(num_bins):\n",
    "        plt.quiver(mesh_x - 0.5 * mesh_u[:, :, i], mesh_y - 0.5 * mesh_v[:, :, i], mesh_u[:, :, i], mesh_v[:, :, i],\n",
    "                   color='red', headaxislength=0, headlength=0, scale_units='xy', scale=1, width=0.002, angles='xy')\n",
    "    # plt.show()\n",
    "    plt.savefig('hog.png')\n",
    "    plt.savefig('./figrues/hog4.png')\n",
    "\n",
    "\n",
    "def extract_hog(im, visualize=False, cell_size=8, block_size=2):\n",
    "    # TODO: implement this function\n",
    "    im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
    "    im = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.normalize(im, None, 0.0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)# normalize\n",
    "    filter_x, filter_y = get_differential_filter()\n",
    "    img_filtered_x = filter_image(img,filter_x)\n",
    "    img_filtered_y = filter_image(img,filter_y)\n",
    "    grad_mag, grad_ang = get_gradient(img_filtered_x,img_filtered_y)\n",
    "    im_hist = build_histogram(grad_mag,grad_ang,cell_size)\n",
    "    # print(im_hist.shape)\n",
    "    im_hist_normalized = get_block_descriptor(im_hist,block_size)\n",
    "    hog = im_hist_normalized.flatten()\n",
    "    if visualize:\n",
    "        visualize_hog(img,hog,cell_size=cell_size,block_size=block_size)\n",
    "    return hog\n",
    "\n",
    "\n",
    "def face_recognition(I_target, I_template):\n",
    "    # TODO: implement this function\n",
    "    hog_template = extract_hog(I_template)\n",
    "    hog_template = hog_template - np.mean(hog_template)\n",
    "\n",
    "    h_tem, w_tem = I_template.shape\n",
    "    h,w = I_target.shape\n",
    "    \n",
    "\n",
    "    tmp_bounding_boxes = np.zeros((h*w,3))\n",
    "    cnt = 0\n",
    "    for i in range(h - h_tem):\n",
    "        for j in range(w - w_tem):\n",
    "            # print(str(i)+\", \" + str(j) )\n",
    "            I_temp = I_target[i:i+h_tem,j:j+w_tem]\n",
    "\n",
    "            hog_image = extract_hog(I_temp)\n",
    "            hog_image = hog_image - np.mean(hog_image)\n",
    "            s = np.dot(hog_image,hog_template)/(np.linalg.norm(hog_image,2)*np.linalg.norm(hog_template,2))\n",
    "            \n",
    "            if s>0.65:\n",
    "                tmp_bounding_boxes[cnt,:] = [j,i,s]\n",
    "                cnt+=1\n",
    "                \n",
    "    bounding_boxes = non_maximum_suppression(tmp_bounding_boxes[:cnt],(h_tem,w_tem))\n",
    "                \n",
    "    return bounding_boxes\n",
    "\n",
    "def non_maximum_suppression(bb_set,box_size):\n",
    "    sorted_bb_set = sorted(bb_set,key = lambda x : x[2], reverse = True)\n",
    "    bounding_boxes = np.zeros((3,))\n",
    "    bounding_boxes = np.r_[[bounding_boxes],[sorted_bb_set[0]]]\n",
    "    for i in range(len(sorted_bb_set)):\n",
    "        # print(str(i) + \": \" + str(len(bounding_boxes)))\n",
    "        target_bb = list(sorted_bb_set[i])\n",
    "        isDiscared = False\n",
    "        for j in range(len(sorted_bb_set)):\n",
    "            if np.abs(getIOU(target_bb,bb_set[j],box_size[0],box_size[1]))>0.5:\n",
    "                if target_bb[2] < bb_set[j,2] : \n",
    "                    isDiscared = True\n",
    "        if not isDiscared:\n",
    "            bounding_boxes = np.r_[bounding_boxes,[target_bb]]\n",
    "    bounding_boxes = bounding_boxes[1:]\n",
    "    return bounding_boxes\n",
    "\n",
    "def getIOU(cor_1,cor_2,h,w):\n",
    "    # this is my own function which calculates the IOU of BB\n",
    "    box1_area = h*w\n",
    "    box2_area = h*w\n",
    "\n",
    "    # obtain x1, y1, x2, y2 of the intersection\n",
    "    x1 = max(cor_1[0], cor_2[0])\n",
    "    y1 = max(cor_1[1], cor_2[1])\n",
    "    x2 = min(cor_1[0] + w, cor_2[0] + w)\n",
    "    y2 = min(cor_1[1]+ h, cor_2[1] + h)\n",
    "\n",
    "    # compute the width and height of the intersection\n",
    "    w = max(0, x2 - x1 + 1)\n",
    "    h = max(0, y2 - y1 + 1)\n",
    "\n",
    "    inter = w * h\n",
    "    iou = inter / (box1_area + box2_area - inter)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def visualize_face_detection(I_target, bounding_boxes, box_size):\n",
    "\n",
    "    hh,ww,cc=I_target.shape\n",
    "\n",
    "    fimg=I_target.copy()\n",
    "    for ii in range(bounding_boxes.shape[0]):\n",
    "\n",
    "        x1 = bounding_boxes[ii,0]\n",
    "        x2 = bounding_boxes[ii, 0] + box_size \n",
    "        y1 = bounding_boxes[ii, 1]\n",
    "        y2 = bounding_boxes[ii, 1] + box_size\n",
    "\n",
    "        if x1<0:\n",
    "            x1=0\n",
    "        if x1>ww-1:\n",
    "            x1=ww-1\n",
    "        if x2<0:\n",
    "            x2=0\n",
    "        if x2>ww-1:\n",
    "            x2=ww-1\n",
    "        if y1<0:\n",
    "            y1=0\n",
    "        if y1>hh-1:\n",
    "            y1=hh-1\n",
    "        if y2<0:\n",
    "            y2=0\n",
    "        if y2>hh-1:\n",
    "            y2=hh-1\n",
    "        fimg = cv2.rectangle(fimg, (int(x1),int(y1)), (int(x2),int(y2)), (255, 0, 0), 1)\n",
    "        cv2.putText(fimg, \"%.2f\"%bounding_boxes[ii,2], (int(x1)+1, int(y1)+2), cv2.FONT_HERSHEY_SIMPLEX , 0.5, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    plt.figure(3)\n",
    "    plt.imshow(fimg, vmin=0, vmax=1)\n",
    "    plt.imsave('result_face_detection.png', fimg, vmin=0, vmax=1)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # correct the path before the submission\n",
    "    # im = cv2.imread('./cameraman.tif', 0)\n",
    "\n",
    "    # im = cv2.imread('./einstein.png',0)\n",
    "    # im = cv2.imread(\"./cat.tif\",0)\n",
    "    # im = cv2.imread(\"./twins.tif\",0)\n",
    "    # hog = extract_hog(im, visualize=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    I_target= cv2.imread('target.png', 0) # MxN image\n",
    "\n",
    "    I_template = cv2.imread('template.png', 0) # mxn  face template\n",
    "\n",
    "    bounding_boxes = face_recognition(I_target, I_template)\n",
    "\n",
    "    I_target_c= cv2.imread('target.png') # MxN image (just for visualization)\n",
    "    \n",
    "    visualize_face_detection(I_target_c, bounding_boxes, I_template.shape[0]) # visualization code\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
